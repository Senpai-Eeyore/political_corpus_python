{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef77e17-aab2-426c-b246-5f4a60cd271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scripts.data_pull as dp\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import text\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://stackoverflow.com/questions/26826002/adding-words-to-stop-words-list-in-tfidfvectorizer-in-sklearn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "porter_stemmer = PorterStemmer()\n",
    "project_stopwords = stopwords.words(\"english\")\n",
    "corpus_specific_stopwords = ['000', '10']\n",
    "project_stopwords.extend(corpus_specific_stopwords)\n",
    "\n",
    "def nltk_tokenizer(str_input):\n",
    "    words = word_tokenize(str_input)\n",
    "    words = porter_stemmer.stem(words)\n",
    "    return words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_61477/1448948591.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mfull_corpus\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_pull\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"combined_corpus\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;31m# Found by Initial Analysis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mcorpus_specific_stopwords\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mENGLISH_STOP_WORDS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"000\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"19\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"10\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dp' is not defined"
     ]
    }
   ],
   "source": [
    "full_corpus = dp.data_pull(\"combined_corpus\")\n",
    "# Found by Initial Analysis\n",
    "corpus_specific_stopwords = text.ENGLISH_STOP_WORDS.union([\"000\", \"19\", \"10\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x_text = full_corpus.text\n",
    "y_bias = full_corpus.art_bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_61477/3649279452.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m x_train, x_test, y_train, y_test = train_test_split(\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mx_text\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_bias\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0mtest_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m.2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m42\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_text' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_text, y_bias,\n",
    "    test_size=.2,\n",
    "    random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(tokenizer=nltk_tokenizer,\n",
    "                             max_features=200)),\n",
    "    ('clf', LogisticRegression()),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with parallel_backend('threading', n_jobs = 5):\n",
    "    text_clf.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(x_test)\n",
    "np.mean(predicted == y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, predicted)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__max_features': (None, 200)\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_clf.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_predicted = gs_clf.predict(x_test)\n",
    "np.mean(gs_predicted == y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_results = pd.DataFrame(gs_clf.cv_results_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, gs_predicted)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coef_values = pd.DataFrame(text_clf[1].coef_,columns=text_clf[0].get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coef_values.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text_clf[0].get_params()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
