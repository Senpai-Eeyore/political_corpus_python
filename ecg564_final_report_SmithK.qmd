---
title: "ECG564 Project Report"
author: "Keenan Smith"
format: pdf
jupyter: python3
---



```{python}
# Importing Pandas and Numpy
import pandas as pd
import numpy as np
# Importing All Pre-processing Steps
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.pipeline import Pipeline
from sklearn.decomposition import TruncatedSVD
# Importing Metrics Module
from sklearn import metrics
# Importing Homegrown Functions
import scripts.blosc_interface as bi
import scripts.corpus_split as cs
```


```{python}
# Reading Full Corpus from Blosc Pickle
full_corpus = bi.blosc_read("./data/tokenized_corpus.dat")
```

```{python}
x_train, x_test, y_train, y_test = cs.corpus_split(full_corpus)
```

```{python}
# Reading in Randomized Search Results
log_reg_cv_results = bi.blosc_read("./data/log_grid_search_result.dat")
log_reg_top5 = log_reg_cv_results.query("rank_test_score <= 5")
```

```{python}
from sklearn.linear_model import LogisticRegression
# Loading Up the Same Pipeline as Random Search
# Updated Values to Optimized
log_clf = Pipeline([
            ('vect', CountVectorizer()),
            ('tfidf', TfidfTransformer()),
            ("svd", TruncatedSVD()),
            ('log_clf', LogisticRegression()) # this needs to be a different solver for LASSO
        ])

# Fitting the Optimized Log Reg Model
log_clf.fit(x_train, y_train)

# Getting Predictions on the testset
predicted = log_clf.predict(x_test)
np.mean(predicted == y_test)

# Printing the results
print(metrics.classification_report(y_test, predicted))

metrics.confusion_matrix(y_test, predicted)
```

```{python}
from sklearn.linear_model import LogisticRegression
# Loading Up the Same Pipeline as Random Search
# Updated Values to Optimized
log_opt_clf = Pipeline([
            ('vect', CountVectorizer(max_features=400, ngram_range=(1,2))),
            ('tfidf', TfidfTransformer()),
            ("svd", TruncatedSVD(n_components=60)),
            ('log_clf', LogisticRegression(penalty="l1", solver = 'saga', C=21.544347, max_iter=1000)), # this needs to be a different solver for LASSO
        ])

# Fitting the Optimized Log Reg Model
log_opt_clf.fit(x_train, y_train)

# Getting Predictions on the testset
predicted = log_opt_clf.predict(x_test)
np.mean(predicted == y_test)

# Printing the results
print(metrics.classification_report(y_test, predicted))

metrics.confusion_matrix(y_test, predicted)
```

```{python}
# Taken from Sklearn's Auto Examples
# Plot the Truncated SVD spectrum
import matplotlib.pyplot as plt

fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))
ax0.plot(
    np.arange(1, log_clf[2].n_components + 1), log_clf[2].explained_variance_ratio_, "+", linewidth=2
)
ax0.set_ylabel("PCA explained variance ratio")

ax0.axvline(
    log_clf[2].n_components,
    linestyle=":",
    label="n_components chosen",
)
ax0.legend(prop=dict(size=12))

# For each number of components, find the best classifier results
results = log_reg_cv_results
components_col = "param_svd__n_components"
best_clfs = results.groupby(components_col).apply(
    lambda g: g.nlargest(1, "mean_test_score")
)

best_clfs.plot(
    x=components_col, y="mean_test_score", yerr="std_test_score", legend=False, ax=ax1
)
ax1.set_ylabel("Classification accuracy (val)")
ax1.set_xlabel("n_components")

plt.xlim(-1, 70)

plt.tight_layout()
plt.show()
```

```{python}
svc_reg_cv_results = bi.blosc_read("./data/svc_grid_search_result.dat")
svc_top5 = svc_reg_cv_results.query("rank_test_score <= 5")
```

```{python}
from sklearn.svm import LinearSVC

svc_clf = Pipeline([
            ('vect', CountVectorizer()),
            ('tfidf', TfidfTransformer()),
            ("svd", TruncatedSVD()),
            ('svc_clf', LinearSVC()),
        ])

svc_clf.fit(x_train, y_train)

predicted = svc_clf.predict(x_test)
np.mean(predicted == y_test)

print(metrics.classification_report(y_test, predicted))

metrics.confusion_matrix(y_test, predicted)
```

```{python}

svc_opt_clf = Pipeline([
            ('vect', CountVectorizer(max_features=400, ngram_range=(1,2))),
            ('tfidf', TfidfTransformer()),
            ("svd", TruncatedSVD(n_components=45)),
            ('svc_clf', LinearSVC(clf_penalty = "l2", C = 0.046415)),
        ])

svc_opt_clf.fit(x_train, y_train)

predicted = svc_opt_clf.predict(x_test)
np.mean(predicted == y_test)

print(metrics.classification_report(y_test, predicted))

metrics.confusion_matrix(y_test, predicted)
```


```{python}
knn_reg_cv_results = bi.blosc_read("./data/knn_grid_search_result.dat")
knn_top5 = knn_reg_cv_results.query("rank_test_score <= 5")
```

```{python}
from sklearn.neighbors import KNeighborsClassifier

knn_clf = Pipeline([
        ('vect', CountVectorizer()),
        ('tfidf', TfidfTransformer()),
        ("svd", TruncatedSVD()),
        ('knn_clf', KNeighborsClassifier()), # this needs to be a different solver for LASSO
    ])

knn_clf.fit(x_train, y_train)

predicted = knn_clf.predict(x_test)
np.mean(predicted == y_test)

print(metrics.classification_report(y_test, predicted))

metrics.confusion_matrix(y_test, predicted)
```

```{python}
knn_opt_clf = Pipeline([
        ('vect', CountVectorizer(max_features=400, ngram_range=(1,1))),
        ('tfidf', TfidfTransformer()),
        ("svd", TruncatedSVD(n_components=60)),
        ('knn_clf', KNeighborsClassifier(n_neighbors = 5)), # this needs to be a different solver for LASSO
    ])

knn_opt_clf.fit(x_train, y_train)

predicted = knn_opt_clf.predict(x_test)
np.mean(predicted == y_test)

print(metrics.classification_report(y_test, predicted))

metrics.confusion_matrix(y_test, predicted)
```

```{python}
forest_cv_results = bi.blosc_read("./data/forest_grid_search_result.dat")
forest_top5 = forest_cv_results.query("rank_test_score <= 5")
```

```{python}
from sklearn.ensemble import RandomForestClassifier

forest_clf = Pipeline([
        ('vect', CountVectorizer()),
        ('tfidf', TfidfTransformer()),
        ("svd", TruncatedSVD()),
        ('forest_clf', RandomForestClassifier()), # this needs to be a different solver for LASSO
    ])

forest_clf.fit(x_train, y_train)

predicted = forest_clf.predict(x_test)
np.mean(predicted == y_test)

print(metrics.classification_report(y_test, predicted))

metrics.confusion_matrix(y_test, predicted)
```

```{python}
forest_opt_clf = Pipeline([
        ('vect', CountVectorizer(max_features=400, ngram_range=(1,2))),
        ('tfidf', TfidfTransformer()),
        ("svd", TruncatedSVD(n_components=60)),
        ('forest_clf', RandomForestClassifier(max_feature="log2",max_depth=35,
        criterion="entropy")), # this needs to be a different solver for LASSO
    ])

forest_opt_clf.fit(x_train, y_train)

predicted = forest_opt_clf.predict(x_test)
np.mean(predicted == y_test)

print(metrics.classification_report(y_test, predicted))

metrics.confusion_matrix(y_test, predicted)
```


